<!DOCTYPE html>
<html><title>webrtc</title>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="bLmaFyyXugiCqSup-eIIIx0B4CngtdF_svyMMKQbS5E" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=10, minimum-scale=0.5, user-scalable=yes">
<meta name="apple-mobile-web-app-capable" content="yes" />
<script src="https://hypothes.is/embed.js" async></script>


<link rel="stylesheet" href="/braindump/css/main.min.56b43bcbc759a196f9dd525bee62bdec45a29ba95902bbab74a4f7ad2ea3e8cb.css"/>

<link rel="stylesheet" href="/braindump/css/links.min.4bf1990b213fb76d2a66153dc6ef9a57d49f536c6baf6e7f19a7948470a38141.css"/>

<link rel="stylesheet" href="/braindump/css/konubinix.min.cf2d0f36945178c647979ee68f1830892e06aa3d481d8913728b5c7462b97f6e.css"/>

<link rel="stylesheet" href="/ipfs/QmQFVQS89fv1XUNFcjwCKDePzckuT9kpuAVNYUwNdEfYcv/css/all.css"/>
<link rel="shortcut icon" href="/ipfs/QmVFwYV7YRZLKU3ybN1hW4jqfyZGPLKJwd8toN2wHz5UAD?a.png" type="image/x-icon" />

<body><header>
  <div>
	<a href="/braindump//"><h5 class="site-title">Konubinix&#39; opinionated web of thoughts</h5></a>
  </div>
  <span>
	<a href="/blog/"><i class="icon fas fa-blog"></i></a>
	<a href="/braindump/posts/"><i class="icon fas fa-brain"></i></a>
    <a href="mailto:konubinixweb@gmail.com"><i class="icon fas fa-envelope-square"></i></a>
    <a href="https://github.com/konubinix"><i class="icon fab fa-github-square"></i></a>
    <a href="https://linkedin.com/in/samuel-loury-61259040"><i class="icon fab fa-linkedin"></i></a>
	<a href="/braindump/graph.html"><i class="icon fas fa-project-diagram"></i></a>
	<a href="/braindump/index.xml"><i class="icon fas fa-rss-square"></i></a>
	<a href="/braindump/tags/"><i class="icon fa fa-tag"></i></a>
	<a href="/braindump/braindump_search"><i class="icon fa fa-search"></i></a>
  </span>
</header>

<div class="grid-container">
  <div class="grid">
    <div class="page" data-level="1">
      <div class="content">
		<p class="lead">
        <h1>Webrtc</h1>
		<span class="badge badge-pill badge-warning"><a href="/braindump/tags/fleeting/">Fleeting</a></span></p>
        <ul>
<li>External reference: <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></li>
<li>External reference: <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></li>
<li>External reference: <a href="https://en.wikipedia.org/wiki/Session_Description_Protocol">https://en.wikipedia.org/wiki/Session_Description_Protocol</a></li>
<li>External reference: <a href="https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment">https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment</a></li>
<li>External reference: <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></li>
<li>External reference: <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></li>
</ul>
<blockquote>
<p>Setting up a call between WebRTC peers involves three tasks:</p>
<ol>
<li>Create a <a href="#a59376fb-5c66-4a03-ae26-4e1e914f0a19">RTCPeerConnection</a> for each end of the call and, at each end, add the local stream from getUserMedia().</li>
<li>Get and share network information: potential connection endpoints are known
as <a href="#aeeb1b3a-513d-45db-b18b-330b257bdfc7">ICE</a> candidates.</li>
<li>Get and share local and remote descriptions: metadata about local media in
<a href="#7d8892cc-6cf2-4997-ab70-1374f0b8bc33">SDP</a> format.</li>
</ol>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p><a href="/braindump/posts/h_264/">H.264</a> is a format that is more universally supported across different browsers</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>AAC finds more universal adoption</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>foundational protocol that powers WebRTC is UDP.</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>DTLS is used within WebRTC to secure and encrypt all data transfers between participants.</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>SCTP and SRTP are used to multiplex the streams and provide both congestion and flow control.</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>every stream sent between participants is encrypted with Secure Real-Time Protocol (SRTP)</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>generate the keys to encrypt the session, WebRTC utilizes DTLS-SRTP</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>signaling server needs to be using the HTTPS protocol, which encrypts the contents sent across the signaling server</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>WebRTC does not handle signaling</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>job of the MCU is to receive media from each participant, decode it, and mix the audio and video from the participants together into a single stream and send it to each participant</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Each node sends it’s transcoded media to the SFU, which then forwards this to all the nodes in the session. Unlike the MCU approach, transcoding happens at the edges and not at the server.</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>SFU based approaches tend to scale very well, while keeping the server load to a minimum</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>simple strategy is to use P2P mode when participants are less than 4, and switch to SFUs when it crosses that threshold. Most open-source SFUs today can scale well to about 20–30 participants.</p>
<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<h2 id="02dcf078-d97b-44fe-a90d-265b30a73eff">topologies</h2>
<h3 id="7eb37ff2-1037-4068-aafe-714b265a8174"><a href="/braindump/posts/peer_to_peer/">peer-to-peer</a></h3>
<blockquote>
<figure><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*jjwBR8mH-wZZ1EO7?a.png">
</figure>

<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<h3 id="964fad68-b2ee-4423-9083-1aba9a88fda8">Multi-point Control Unit</h3>
<blockquote>
<figure><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*o_JaFQf2yBgwBJRN?a.png">
</figure>

<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<h3 id="5d391484-fa3f-4c00-9710-9e957bcdbd8a">Selective Forwarding Unit</h3>
<blockquote>
<figure><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*V8yDNbdSy6lOsgC_?a.png">
</figure>

<p>&mdash; <a href="https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9">https://medium.com/secure-meeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-e2aea14c80f9</a></p>
</blockquote>
<h2 id="03a6d944-3d82-4c62-89a3-7227201cd360">more than two peers</h2>
<ul>
<li>
<p>External reference: <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a>
Blog | Voximplant.com</p>
<blockquote>
<p>what if you want to hold a meeting with more than two people? How can you leverage powerful WebRTC APIs to build a multi party conferencing application?</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
</li>
</ul>
<h3 id="65314a7f-0ba8-420b-85f2-53bd833f89d1">selective forwarding unit</h3>
<blockquote>
<p>selective forwarding unit (SFU) as the preferred method of extending WebRTC to multi party conferencing</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>approach is to build a mesh topology in which every participant sends and receives media from every other participant</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>mesh topology quickly reaches scalability limitations. It consumes a lot of bandwidth and client processing power to manage all the media streams.</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>To increase scalability, you need to build a hub-and-spoke topology by inserting a media server into the network</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Hub-and-spoke topologies can increase latency because media must traverse a longer path from sender to receiver</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>hub-and-spoke topology introduces an intermediary between clients that breaks the WebRTC end-to-end security feature.</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Without the incorporation of additional end-to-end encryption (E2EE) techniques, a bad actor could potentially monitor the media as it passes through the media server</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Two types of media servers can be used to implement the hub-and-spoke topology: The multipoint control unit (MCU); and the selective forwarding unit (SFU).</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>MCU decodes each received media stream, rescales them, creates a new tiled stream featuring all participants, encodes and sends it to all clients.</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>MCU is an expensive and compute-intensive infrastructure element</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>MCU completely relieves clients of local processing and it is the most efficient of all the alternatives in its bandwidth utilization.</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>SFU receives media streams from each participant and merely forwards them to the other participants without changes</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>, in an SFU architecture, the client with the least bandwidth dictates the video quality available to all clients</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Simulcast SFU</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>designed to prevent a few clients with limited bandwidth resources from degrading the video quality available to all</p>
<p>&mdash; <a href="https://voximplant.com/blog/an-introduction-to-selective-forwarding-units">https://voximplant.com/blog/an-introduction-to-selective-forwarding-units</a></p>
</blockquote>
<h2 id="97101ea9-1c29-4a3f-8e61-625d9cc8d7d1">peerjs</h2>
<ul>
<li>
<p>External reference: <a href="https://peerjs.com/">https://peerjs.com/</a></p>
<blockquote>
<p>PeerJS wraps the browser&rsquo;s WebRTC implementation to provide a complete,
configurable, and easy-to-use peer-to-peer connection API. Equipped with nothing
but an ID, a peer can create a P2P data or media stream connection to a remote
peer.</p>
<p>&mdash; <a href="https://peerjs.com/">https://peerjs.com/</a></p>
</blockquote>
<p>They even provide the code for a simple <a href="#0a72cbf5-f05a-4615-b67f-8603bc783e2b">signaling</a> server in <a href="https://github.com/peers/peerjs-server">https://github.com/peers/peerjs-server</a></p>
<p>Beware though, that it needs a recent enough browser.</p>
<blockquote>
<p>Browser support</p>
<table>
  <thead>
      <tr>
          <th>Firefox</th>
          <th>Chrome</th>
          <th>Edge</th>
          <th>Safari</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>80+</td>
          <td>83+</td>
          <td>83+</td>
          <td>15+</td>
      </tr>
  </tbody>
</table>
<p>We test PeerJS against these versions of Chrome, Edge, Firefox, and Safari
with BrowserStack to ensure compatibility. It may work in other and older
browsers, but we don&rsquo;t officially support them. Changes to browser support
will be a breaking change going forward.</p>
<p>&mdash; <a href="https://github.com/peers/peerjs">https://github.com/peers/peerjs</a></p>
</blockquote>
</li>
</ul>
<h2 id="b27079d7-380a-41fe-9139-ed16aba0d7a2">debug</h2>
<blockquote>
<p>Take a look at chrome://webrtc-internals. This provides WebRTC stats and debugging data</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<h2 id="b5988f79-3315-4128-bbce-0cd8441e724c">shim adapter</h2>
<blockquote>
<p>script src=&quot;<a href="https://webrtc.github.io/adapter/">https://webrtc.github.io/adapter/</a></p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>adapter.js is a shim to insulate apps from spec changes and prefix differences. (Though in fact, the standards and protocols used for WebRTC implementations are highly stable, and there are only a few prefixed names.)</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<h2 id="da5b76dc-0516-4c44-b981-85703d4fd6c2">Security</h2>
<blockquote>
<p>Encryption is mandatory for all WebRTC components, and its JavaScript APIs can only be used from secure origins (HTTPS or localhost).</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<h2 id="dbc94727-ccfb-4f82-a660-66f6b72a9834">Sending Data</h2>
<h3 id="e52e0359-1ed3-4bf5-b737-a8741911ce1a">RTCDataChannel</h3>
<blockquote>
<p>syntax of RTCDataChannel is deliberately similar to WebSocket, with a send() method and a message event.</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<h2 id="33318641-f880-472f-8e4f-0b076c066898">Communication path</h2>
<blockquote>
<p>WebRTC is designed to work peer-to-peer, so users can connect by the most direct
route possible</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Once RTCPeerConnection has that information, the ICE magic happens
automatically. RTCPeerConnection uses the ICE framework to work out the best
path between peers, working with STUN and TURN servers as necessary</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<h3 id="a59376fb-5c66-4a03-ae26-4e1e914f0a19">RTCPeerConnection</h3>
<blockquote>
<p>RTCPeerConnection is the API used by WebRTC apps to create a connection between
peers, and communicate audio and video.</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<h3 id="830c9257-f881-4cab-aa9b-4ce5bbbbdc02"><a href="/braindump/posts/network_address_translation/">NAT</a> traversal</h3>
<dl>
<dt>STUN</dt>
<dd>to find an IP that crosses the NAT</dd>
<dt>TURN</dt>
<dd>to relay data if STUN did not find an IP to cross the NAT</dd>
</dl>
<blockquote>
<p>WebRTC APIs use STUN servers to get the IP address of your computer, and TURN
servers to function as relay servers in case peer-to-peer communication fails</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>In other words, a STUN server is used to get an external network address and
TURN servers are used to relay traffic if direct (peer-to-peer) connection
fails.</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<h4 id="6023c0da-e7b5-476c-be50-6cb4d7b133cc">Session Traversal Utilities for NAT</h4>
<blockquote>
<ul>
<li>
<p>External reference: <a href="https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/">https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/</a>
app uses a STUN server to discover its IP:port from a public
perspective. This process enables a WebRTC peer to get a publicly accessible
address for itself and then pass it to another peer through a signaling
mechanism in order to set up a direct link. (In practice, different NATs
work in different ways and there may be multiple NAT layers, but the
principle is still the same.)</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</li>
</ul>
</blockquote>
<!--quoteend-->
<blockquote>
<p>STUN servers live on the public internet and have one simple task - check
the IP:port address of an incoming request (from an app running behind a
NAT) and send that address back as a response</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Sometimes, you can use a protocol called STUN (Session Traversal Utilities for
NAT) that allows clients to discover their public IP address and the type of NAT
they are behind. This information is used to establish the media connection. In
most cases, a STUN server is only used during the connection setup and once that
session has been established, media will flow directly between the peer and the
Video Gateway (<a href="/braindump/posts/webrtc/">WebRTC</a>).</p>
<p>&mdash; <a href="https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/">https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>However, even if we setup properly a STUN server, there are very restrictive
corporate networks (e.g: UDP traffic forbidden, only 443 TCP allowed…), which
will require clients to use a TURN (Traversal Using Relays around NAT) server to
relay traffic if direct (peer to Video Gateway) connection fails. In these
cases, you can install our TURN server (in another instance) to solve these
issues</p>
<p>&mdash; <a href="https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/">https://blog.ivrpowers.com/post/technologies/what-is-stun-turn-server/</a></p>
</blockquote>
<h4 id="d8bedf8a-b1ef-4ae3-9dac-57d5ea2e5dd7">Traversal Using Relays around NAT</h4>
<blockquote>
<p>Every TURN server supports <a href="#6023c0da-e7b5-476c-be50-6cb4d7b133cc">STUN</a>. A TURN server is a <a href="#6023c0da-e7b5-476c-be50-6cb4d7b133cc">STUN server</a> with additional built-in relaying functionality.</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>TURN is used to relay audio, video, and data streaming between peers, not <a href="#0a72cbf5-f05a-4615-b67f-8603bc783e2b">signaling</a> data!</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<h3 id="aeeb1b3a-513d-45db-b18b-330b257bdfc7">Interactive Connectivity Establishment</h3>
<blockquote>
<p>expression ‘finding candidates&rsquo; refers to the process of finding network interfaces and ports using the  ICE framework.</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Interactive Connectivity Establishment (ICE) is a technique used in computer
networking to find ways for two computers to talk to each other as directly
as possible in <a href="/braindump/posts/peer_to_peer/">peer-to-peer</a> networking</p>
<p>&mdash; <a href="https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment">https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Alice and Eve also need to exchange network information. The expression &ldquo;finding candidates&rdquo; refers to the process of finding network interfaces and ports using the ICE framework.</p>
<ul>
<li>Alice creates an RTCPeerConnection object with an onicecandidate handler.</li>
<li>The handler is called when network candidates become available.</li>
<li>In the handler, Alice sends stringified candidate data to Eve through their
signaling channel.</li>
<li>When Eve gets a candidate message from Alice, she calls addIceCandidate() to
add the candidate to the remote peer description</li>
</ul>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>ICE tries to find the best path to connect peers. It tries all possibilities in
parallel and chooses the most efficient option that works. ICE first tries to
make a connection using the host address obtained from a device&rsquo;s operating
system and network card. If that fails (which it will for devices behind NATs),
ICE obtains an external address using a <a href="#6023c0da-e7b5-476c-be50-6cb4d7b133cc">STUN</a> server and, if that fails, traffic
is routed through a TURN relay server</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<h2 id="7e4f5669-3d1b-4243-8925-33f5243a2bad">JavaScript Session Establishment Protocol</h2>
<ul>
<li>External reference: <a href="https://rtcweb-wg.github.io/jsep/">https://rtcweb-wg.github.io/jsep/</a></li>
</ul>
<blockquote>
<p><a href="#7e4f5669-3d1b-4243-8925-33f5243a2bad">JSEP</a> requires the exchange between peers of offer and answer, the media metadata
mentioned above. Offers and answers are communicated in Session Description
Protocol (<a href="#7d8892cc-6cf2-4997-ab70-1374f0b8bc33">SDP</a>) format</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>this document describes the JavaScript Session Establishment Protocol (JSEP)
that allows for full control of the signaling state machine from JavaScript</p>
<p>&mdash; <a href="https://rtcweb-wg.github.io/jsep/">https://rtcweb-wg.github.io/jsep/</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>JSEP assumes a model in which a JavaScript application executes inside a runtime
containing <a href="/braindump/posts/webrtc/">WebRTC</a> APIs</p>
<p>&mdash; <a href="https://rtcweb-wg.github.io/jsep/">https://rtcweb-wg.github.io/jsep/</a></p>
</blockquote>
<h2 id="7d8892cc-6cf2-4997-ab70-1374f0b8bc33">Session Description Protocol</h2>
<blockquote>
<p>Session Description Protocol (SDP) is a format for describing multimedia communication sessions for the purposes of announcement and invitation.[</p>
<p>&mdash; <a href="https://en.wikipedia.org/wiki/Session_Description_Protocol">https://en.wikipedia.org/wiki/Session_Description_Protocol</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>gory detail:</p>
<ul>
<li>Alice creates an <a href="#a59376fb-5c66-4a03-ae26-4e1e914f0a19">RTCPeerConnection</a> object.</li>
<li>Alice creates an offer (an <a href="#7d8892cc-6cf2-4997-ab70-1374f0b8bc33">SDP</a> session description) with the RTCPeerConnection createOffer() method.</li>
<li>Alice calls setLocalDescription() with her offer.</li>
<li>Alice stringifies the offer and uses a <a href="#0a72cbf5-f05a-4615-b67f-8603bc783e2b">signaling</a> mechanism to send it to Eve.</li>
<li>Eve calls setRemoteDescription() with Alice&rsquo;s offer, so that her
RTCPeerConnection knows about Alice&rsquo;s setup.</li>
<li>Eve calls createAnswer() and the success callback for this is passed a local
session description - Eve&rsquo;s answer.</li>
<li>Eve sets her answer as the local description by calling setLocalDescription().</li>
<li>Eve then uses the signaling mechanism to send her stringified answer to Alice</li>
</ul>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Alice sets Eve&rsquo;s answer as the remote session description using setRemoteDescription().</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Signaling is a process used in WebRTC to detect peers; exchange session descriptions to setup media ports; and helps share everything used for initial handshake.</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Approximately all WebRTC experiments rely on channels. &ldquo;Channel&rdquo; is a term used in realtime protocols like WebSocket to make sure data is transmitted privately over (100%) relevant clients.</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Channels are created dynamically for each peer; to make sure SDP/ICE is exchanged among relevant users.</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>What about LAN or intranet?</p>
<p>You always need a signaling gateway; whether it installed publicly or privately. A gateway can be a copy/paste mechanism or a realtime protocol.</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Signaling is used to detect peers; and exchange prerequisites to setup media connections.</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>ICE which is stands for interactive connectivity establishment is a protocol used to capture public IP addresses of the user. It let us know:</p>
<p>Public IP addresses of the user
It is ipv4 or ipv6
UDP is blocked or not; otherwise fallback to TCP; otherwise fallback to custom protocol</p>
<p>&mdash; <a href="https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html">https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html</a></p>
</blockquote>
<h2 id="0a72cbf5-f05a-4615-b67f-8603bc783e2b">signaling</h2>
<blockquote>
<p>WebRTC uses RTCPeerConnection to communicate streaming data between browsers,
but also needs a mechanism to coordinate communication and to send control
messages, a process known as signaling</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Signaling methods and protocols are not specified by WebRTC</p>
<p>&mdash; <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">https://codelabs.developers.google.com/codelabs/webrtc-web</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>If you don&rsquo;t want to roll your own, there are several WebRTC signaling servers available</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Whatever you choose, you need an intermediary server to exchange signaling
messages and app data between clients.</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>message service for signaling needs to be bidirectional: client to server and server to client</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>the EventSource API has been widely implemented. This enables server-sent events - data sent from a web server to a browser client through HTTP.</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>WebSocket is a more-natural solution, designed for full duplex client–server communication</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>also possible to handle signaling by getting WebRTC clients to poll a messaging server repeatedly through Ajax, but that leads to a lot of redundant network requests, which is especially problematic for mobile devices</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>design of <a href="/braindump/posts/socket_io/">Socket.io</a> makes it simple to build a service to exchange messages and Socket.io is particularly suited to WebRTC signaling because of its built-in concept of rooms</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>signaling protocols and mechanisms are not defined by WebRTC standards</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>Signaling is the process of coordinating communication</p>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--quoteend-->
<blockquote>
<p>exchange the following information:</p>
<ul>
<li>Session-control messages used to open or close communication</li>
<li>Error messages</li>
<li>Media metadata, such as codecs, codec settings, bandwidth, and media types</li>
<li>Key data used to establish secure connections</li>
<li>Network data, such as a host&rsquo;s IP address and port as seen by the outside world</li>
</ul>
<p>&mdash; <a href="https://web.dev/articles/webrtc-infrastructure">https://web.dev/articles/webrtc-infrastructure</a></p>
</blockquote>
<!--more-->
<h2 id="notes-linking-here">Notes linking here</h2>
<ul>
<li><a href="/braindump/posts/aiortc/">aiortc</a></li>
<li><a href="/braindump/posts/aiortc_to_create_a_remote_web_camera_with_an_android_phone/">aiortc to create a remote web camera with an android phone</a></li>
<li><a href="/braindump/posts/go2rtc_to_use_an_android_device_as_webcam/">go2rtc to use an android device as webcam</a></li>
<li><a href="/braindump/posts/afterlife_for_my_phones/#f9d42af6-37fd-47d2-8d24-26ce2dd4f9b3">i9300</a></li>
<li><a href="/braindump/posts/socket_io/">Socket.IO</a></li>
<li><a href="/braindump/posts/stopmotion_android_apps/">stopmotion android apps</a></li>
<li><a href="https://konubinix.eu/blog/posts/use_the_camera_with_kivy_on_android/?title=use_the_camera_with_kivy_on_android#">use the camera with kivy on android</a> (blog)</li>
<li><a href="/braindump/posts/vdo_ninja/">VDO.Ninja</a></li>
</ul>
<h2 id="permalink"><a href="https://konubinix.eu/braindump/eab96985-8452-406c-9631-6f219794f9c5?title=webrtc">Permalink</a></h2>
      </div>
	  <aside class="date"><time>Last updated: 04 Jan 2025</time></aside>
	  <aside class="date"><time>Published&nbsp;&nbsp;&nbsp;: 05 Jan 2024</time></aside>
    </div>
  </div>
</div>

<script src="/braindump/js/URI.js" type="text/javascript"></script>

<script src="/braindump/js/page.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
